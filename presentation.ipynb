{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Great Expectations in the Forecasting Team of Maersk\n",
    "\n",
    "* Forecasting Team ü•ë at Maersk\n",
    "* Data and machine learning pipelines in k8s\n",
    "* Implementation of great expectations\n",
    "* Pain & Gain\n",
    "\n",
    "___\n",
    "\n",
    "Micha B A Kunze - michabenachim.kunze@maersk.com | [@mbakunze](https://github.com/mbakunze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forecasting Team ü•ë of Maersk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maersk\n",
    "\n",
    "* largest ocean container shipping company (~20-25% of global volume)\n",
    "* ~ 700 vessels (owned + chartered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Team ü•ë\n",
    "We build forecasts of future demand - together:\n",
    "\n",
    "Andreas, Edward, Lasse, Hans, Karin, Julija, Henrik, Ricko, Luca, Marco, Andreas, Micha, S√∏ren and Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building Forecasts\n",
    "\n",
    " * daily batch processing of __full__ historical datasets\n",
    " * crucial that data is historically accurate (at which time did you know what)\n",
    " * computationally heavy jobs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ### Tech Stack:\n",
    " * Git\n",
    " * Docker\n",
    " * Kubernetes\n",
    " * Python, R, Spark\n",
    " * Azure Blob Storage\n",
    " * Datadog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How we work\n",
    "\n",
    " * everything is code, and code lives in git\n",
    " * DevOps / GitOps\n",
    " * all running code is containerized\n",
    " * highly collaborative: software engineers | data scientists | data engineers pair to solve challenges\n",
    " * multiple forecasting products in production -> millions of forecasts a day\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data and Machine Learning Pipelines in Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How We Build Pipelines\n",
    "\n",
    " * use pippi to run pipelines (in-house built orchestrator)\n",
    " * separate functions (-> code) and data (-> config)\n",
    " * use git branching to build new/modify pipeline code\n",
    " * datasets are saved as __immutable__ snapshots for each run\n",
    " * compute jobs are implemented as k8s __jobs__ that get called when upstream data changes\n",
    " \n",
    " Allows us to isolate concerns and develop in parallel.\n",
    " \n",
    "![pippi_r2l](assets/pippi_r2l.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this might be might the code for you data pipeline\n",
    "# runs locally the same as on k8s\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def most_important_transform(source01_path: str, source02_path: str, destination_path: str):\n",
    "    source01_df = pd.read_parquet(source01_path)\n",
    "    source02_df = pd.read_parquet(source02_path)\n",
    "    \n",
    "    transformed_df = source01_df.merge(source02_df, on=\"order_id\", how=\"left\")\n",
    "    \n",
    "    transformed_df.to_parquet(destination_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your Configuration Could Then Look Like This:\n",
    "\n",
    "___\n",
    "\n",
    "```bash\n",
    "SOURCE01_STORAGE_ACCOUNT=prod\n",
    "SOURCE01_DATASET=orders\n",
    "\n",
    "SOURCE02_STORAGE_ACCOUNT=prod\n",
    "SOURCE02_DATASET=contracts\n",
    "\n",
    "DESTINATION_STORAGE_ACCOUNT=prod\n",
    "DESTINATION_DATASET=enriched_orders\n",
    "\n",
    "JOB_EXECUTION_TARGET=ge_entrypoint python -m most_important_transform\n",
    "\n",
    "SCHEDULER_STRATEGY=Any\n",
    "```\n",
    "___\n",
    "_Note: `ge_entrypoint` is a simple python wrapper_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Functional Data Engineering\n",
    "\n",
    "Functional as in _functional programming_. Many of the principles lend themsleves well to data engineering.\n",
    "\n",
    " * __immutable data__ - snapshot all the data!\n",
    " * __idempotent functions__ - data pipelines are functions that have no side effects\n",
    " * __reproducibility__ - foundation of the scientific method (and sanity)\n",
    " \n",
    " \n",
    "___ \n",
    " _Check:_ Maxime Beauchemin, founder of Airflow\n",
    "  * [medium post on functional data engineering](https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)\n",
    "  * [youtube video on functional data engineering](https://youtu.be/4Spo2QRTz1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Immutability\n",
    "\n",
    "Data snapshotting:\n",
    "\n",
    "![pippi-snaphoting](assets/pippi-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Immutability\n",
    "\n",
    "Data & code dependencies:\n",
    "\n",
    "![pippi-snaphoting](assets/pippi-snaphots.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reproducibility\n",
    "\n",
    "Foundation to do scientific/analytics work. \n",
    "\n",
    "Immutability is a key enabler of reproducibility, and so is idempotency. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementation of Great Expectations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run great-expectations \n",
    "\n",
    "\n",
    "* we simply run great-expectations in our docker containers\n",
    "* each forecasting product has its own GE setup (which is the default setup)\n",
    "* we follow the simple convention that `expectation suite name` =  `dataset name`\n",
    "    - our `ge_entrypoint` script only matches the above convention to run the proper tests\n",
    "    \n",
    "* when GE fails we break the pipeline (with some pretty logging) and we get alerts via our default DataDog:PagerDuty setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How We Use Data Validation\n",
    "\n",
    "* validate source AND destination data\n",
    "* breack on failure to validate\n",
    "* if output check fails - save data in \"failed\" location for inspection/debugging\n",
    "* data checks are running **decoupled** from the pipeline code\n",
    "\n",
    "![ge_flow](assets/ge_entrypoint_logic.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Test Coverage\n",
    "\n",
    "* we wrote some simple scripts to help us cover datasets in all our forecasting products\n",
    "* we use a data cli in our GE notebooks to easily profile data and edit expectations\n",
    "    - _we only use files and are note making use of the data source configs of GE_\n",
    "    \n",
    "       \n",
    "```bash\n",
    "‚ùØ poetry run ge_coverage\n",
    "*** Data Validation Coverage Report ***\n",
    "=================================================================\n",
    "Dataset Name                                           | covered?\n",
    "-----------------------------------------------------------------\n",
    "dataset1                                               | ‚ùå\n",
    "dataset1-final_v1                                      | ‚úÖ\n",
    "dataset1-final_v2                                      | ‚úÖ\n",
    "dataset1-draft_v1                                      | ‚ùå\n",
    "dataset2-final                                         | ‚úÖ\n",
    "dataset1-intermediate_v1                               | ‚úÖ\n",
    "all-the-data                                           | ‚úÖ\n",
    "features-new                                           | ‚úÖ\n",
    "feature_v2                                             | ‚úÖ\n",
    "awesome-forecast-for-real-this-time                    | ‚ùå\n",
    "=================================================================\n",
    "Summary:\n",
    "-----------------------------------------------------------------\n",
    "Datasets covered: 7/10\n",
    "Coverage percentage: 70 %  üòê\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pain & Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  üí• Things Break Constantly üí•\n",
    "\n",
    " * not a question of IF, but only of WHEN\n",
    " * when we first put great expectation into production we were breaking many data pipelines that turned out to actually be OK üò±\n",
    "  - we started to learn about our data quality\n",
    "  - iterative process\n",
    " * data quality is part of our constant improvement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Validation in Team ü•ë\n",
    "\n",
    "* data validation in production for all our forecasting products for ~3 month\n",
    "* already prevented many incidents üí™\n",
    "    - prevented us from outputting bad quality forecasts\n",
    "    - broke data pipelines where we had incomplete data due to a race condition we hit upstream (which previously got by unnoticed)\n",
    "* lead to investigation of data quality issues and improvements\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Validation in Team ü•ë\n",
    "\n",
    "* the whole team collaborates on data quality and testing issues ü§ù\n",
    "* extensibility and notebook templating allowed us to implement GE fast ‚ö°Ô∏è\n",
    "* automatic data and expectation documention using GE in mkdocs üìñ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}